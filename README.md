# FDS-2HW_testing
We will re-derive and implement logistic regression and optimize the parameters with Gradient Descent and with the Newton's method. Also, in this exercise we will re-derive and implement Gassian Discriminant Analysis. We will use datasets generated from the make_classification function from the SkLearn library. 
The topics covered: Logistic Regression with Gradient Ascent, Logistic Regression with non linear boundaries( Polynomial features for logistic regression), Multinomial Classification (Softmax Regression), Multinomial Naive Bayes.
